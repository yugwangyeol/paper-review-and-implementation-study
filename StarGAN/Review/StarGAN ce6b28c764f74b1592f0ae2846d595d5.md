# StarGAN

https://festive-impatiens-b9a.notion.site/StarGAN-d200ac246ab14259ba82f23bb3b89972

# 용어 정리

- attribute: 이미지에 있는 의미있는 특징을 말함,
    
    → 성별, 나이, 헤어 컬러가 있음
    

- attibute value: attibute의 값을 말함
    
    → 헤어 컬러인 경우 흑발/금발/갈색을 말함
    

- domain: 같은 attribute value를 공유하는 이미지들의 집합
    
    → 여성의 이미지들은 하나으 domain을 구성하고 남성의 이미지는 또 다른 domain을 구성
    

# StarGAN

- 최근의 image-to-image translation은 2개 이상의 도메인을 다루는데 scalability와 robustness 제한해옴
- 이는 서로 다른 모델들이 각 이미지 도메인 쌍에 독립적으로 만들어졌기 떄문, 이러한 한계점을 극복하고자 StarGAN을 제한함

- StarGAN은 image-to-image translation을 sacalable한 접근으로, 단 하나의 모델을 사용하여 여러가지의 domain에 대해 image-to-image translation을 할 수 있음
- 이러한 StarGAN의 특징은 하나의 네트워크안에서 다양한 도메인의 데이터셋에 대해 동시에 학습시키는 것을 가능하게함
- StarGAN이 기존모델에 비해 유연하게 이미지를 translate하게 만들어 우수한 퀄리티를 만들어냄

![Untitled](StarGAN%20ce6b28c764f74b1592f0ae2846d595d5/Untitled.png)

# Introduction

## Image-to-Image translation (I2I)

- 주어진 이미지에서 특정 부분을 다른 다른 이미지로 변경하는 것을 말함
    
    → 예를 들어 검은 머리에서 갈색 머리로 바꾸는 것이 있음
    
- 대표적인 예로는 CycleGAN이 있음

## Cross-domain models와 StarGAN

- 기존 모델(CycleGAN,DiscoGAN,pix2pix,CGAN)에서는 한 개의 특징만을 학습해서 변환하는 방법을 제시
- 기존모델에서 다양한 도메인으로 변환하려면 도메인 k당 k(k-1) 개의 네트워크가 필요하기 때문에 비효율적임

![Untitled](StarGAN%20ce6b28c764f74b1592f0ae2846d595d5/Untitled%201.png)

- Cross-domain models: 다른 도메인 사이에서 이미지를 translation 시키기 위해서는 4(4-1) = 12개의 네트워크가 필요
- 각 데이터셋이 부분적으로 라벨링 되어있기 때문에, jointly training 이 불가능
- StarGAN: 다중 도메인에서의 학습 데이터를 얻고, 단일 generator(G)로 모든 가능한 도메인 사이의 맵핑을 학습

- 고정된 translation, 예를 들면 흑발에서 금발로 바꾸는 translation을 학습시키는 대신에, 이 single generator는 **이미지와 도메인 정보를 모두 인풋으로 집어넣고** 유연하게 이미지를 알맞은 도메인으로 바꾸는 것을 학습
- 이러한 도메인 정보들을 표현하는데에는 **binary나 one-hot vector**와 같은 형식을 사용
- 학습하는 동안 **랜덤하게 타겟 도메인 라벨을 만들어내고** 모델이 유연하게 이미지를 타겟 도메인으로 변환하도록 학습
- 이에 더해, **mask vector**를 도메인 라벨에 추가함으로써, joint 학습이 가능하도록 함
- 모델이 모르는 라벨을 *무시* 할 수 있고 특정 데이터셋의 라벨들에 초점을 맞출 수 있음

**1. StarGAN : 하나의 generator, discriminator만을 이용하여 multiple domains간의 매핑을 학습.**

**2. 다양한 데이터셋 간의 multi-domain image translation을 mask vector method를 통해 학습한 방법**

**3. 얼굴 특징 변환과 같은 task에 대한 결과들.**

# Star Generative Adversarial Networks

![Untitled](StarGAN%20ce6b28c764f74b1592f0ae2846d595d5/Untitled%202.png)

- (a) D : Real Image와 Fake Image를 구별, 동시에 Real Image 일 때 그것과 상응하는 domain을 분류해내는 것을 학습
- (b) G : Input으로 image와 Target domain label을 받고 Fake image를 생성
- (c) G : Original domain label을 가지고 Fake Imge를 다시 Original Image로 복원
- (d) D : Real Image와 구분 할 수 없고 D에 의해 Target domain으로 분류 가능한 이미지를 생성

### **Generator**

1. 먼저, input으로는 image 뿐만 아니라 target domain label을 같이 넣어줌
- 이 target label은 random하게 생성되어 input image를 flexeble하게 translate하도록 함

1. 두번째로, **같은 generator(G)**를 사용하여 CycleGAN의 형태를 사용함
- 즉, target domain label에 해당하는 이미지로 변환한 다음에 다시 원래 domain label에 해당하는 이미지로 reconstruction함
- 일반 CycleGAN과 다른 점은 generator를 공통으로 하나만 사용한다는 점

1. 마지막으로, 만들어진 이미지는 **Discriminator(D)**에 input으로 입력되고 generated image가 real이 되도록, 또 target label이 분류모델을 통해 나오도록 학습

### **Discriminator**

1. Ground-Truth image와 Generated Image를 input으로 받음

1. 이전과 같이 real image와 fake image를 구별하고, 실제 이미지의 domain label이 나오도록 분류모델을 학습

### **Conditional Input**

1. 먼저 target domain label을 1x12차원 vector(5: celebA, 5: ReFD, 2: mask vector), input image를 1x3x64x64 tensor라 가정
2. 그 다음 target domain label을 1x1 tensor로 reshape한다. 1x12−>1x12x1x1
    
    1x12−>1x12x1x1
    
3. 그리고 이 1x1 tensor를 이미지의 width, height크기로 repeat한다. 1x12x1x1−>1x12x64x64
    
    1x12x1x1−>1x12x64x64
    
4. 마지막으로 이 tensor와 input image를 depth-wise concat함

### Adversarial Loss

- 만들어진 이미지가 진짜 이미지와 구분되지 않도록 만들기 위해, original GAN과 마찬가지로 adversarial loss를 이용

![Untitled](StarGAN%20ce6b28c764f74b1592f0ae2846d595d5/Untitled%203.png)

- generator G가 image G(x,c)를 만들어내고 D는 진짜와 가짜 이미지들을 구분하는 역할
- 여기서 D_src는 D에 의해 주어진 sources에 관한 확률 분포
- G는 위의 loss 함수를 최소화하고자 하고 D는 최대화하고자 함(original GAN과 같음)

- $D_{src}(x)$ : Discriminator가 이미지를 진짜인지 진짜인지 판별하는 것
- G: loss 함수를 최소화
- D: loss 함수를 최대화

- 간단하게 Generator G는 최대한 ground-truth와 비슷한 이미지를 만들어서 Discriminator D를 속이도록 학습을 하고, Discriminator D는 Generator G에서 생성된 fake image와 real image를 구별할 수 있도록 학습

### Domain Classification Loss

- 주어진 인풋 이미지 x와 타겟 도메인 라벨 c에 대해 목표는 x를 타겟 도메인 c로 분류된 output image y로 변환하는 것
    
    → 여성 이미지 x를 타겟 도메인 라벨  c(남성)으로 변환하는 것
    
- auxiliary classifier를 추가하고 D와 G를 최적화하는데 사용

loss가 두가지로 나눔

1) 첫번째는 **D**를 최적화하기 위해 사용되는 *진짜 이미지*들에 대한 도메인 분류 loss

![Untitled](StarGAN%20ce6b28c764f74b1592f0ae2846d595d5/Untitled%204.png)

- 이 함수를 최소화하기 위해서, D는 진짜 이미지 x를 original 도메인 c’에 분류하는 것을 학습
- $D_{cls}(c'|x)$가 1에 가까워지도록 학습
- $D_{cls}(c'|s)$는 real image x가 주어졌을 때 D가 계산해낸 domain label c’일 확률

2) 두번째는 **G**를 최적화하기 위한 *가짜 이미지*들에 대한 도메인 분류 loss

![Untitled](StarGAN%20ce6b28c764f74b1592f0ae2846d595d5/Untitled%205.png)

- 위를 최소화하기 위해 D_cls(c|G(x,c))를 1에 가까워지도록 G를 학습
- G는 target domain c로 분류될 수 있는 이미지를 생성하도록 loss를 최소화 하려 함

### Reconstruction Loss

- *Adversarial loss*와 *classification loss*를 최소화하기 위해, **G**는 진짜같은, 올바른 타겟 도메인에 분류되는 이미지들을 만들어내도록 학습
- 하지만, 위의 Loss를 최소화하는 것은 변환된 이미지가 인풋 이미지들의 내용을 보존한다는 것을 보장하지 않음
- 이러한 문제를 완화하기 위해서, 이 논문에서는 generator에 **"Cycle consistency loss"**를 적용

![Untitled](StarGAN%20ce6b28c764f74b1592f0ae2846d595d5/Untitled%206.png)

- Generator G는 변환된 이미지 G(x,c)와 오리지날 도메인 라벨 c'를 인풋으로 하고, 오리지날 이미지 x를 다시 생성해내도록 시도
- 여기서 L1 norm을 사용
- 하나의 generator를 두번 사용하는데 첫번째는 오리지날 이미지 인풋 x를 타겟 도메인으로 변환시킬 때이고, 두번째는 변환된 이미지를 오리지날 이미지로 reconstruct할 때임(Encoder-Decoder와 같은 역할)

### Full objective

- 위에서 나온 loss들을 모두 정리해보면 다음과 같은 식을 얻음

![Untitled](StarGAN%20ce6b28c764f74b1592f0ae2846d595d5/Untitled%207.png)

![Untitled](StarGAN%20ce6b28c764f74b1592f0ae2846d595d5/Untitled%208.png)

![Untitled](StarGAN%20ce6b28c764f74b1592f0ae2846d595d5/Untitled%209.png)

- 하이퍼 파라미터인 lambda cls와 lambda rec를 통해 (도메인 분류 loss + reconstruction loss)/ adversarial loss 간의 중요도를 조절
- 각각 1과 10을 사용

# ****Training with Multiple Datasets****

- StarGAN의 중요한 장점중의 하나는 다른 라벨들을 가지고 있는 여러개의 데이터셋을 동시에 처리할 수 있다는 점
- 그러나, 여러개의 데이터셋으로부터 학습시킬 때, **각 데이터셋에서의 라벨 정보가 부분적으로만 알려져있다는 것이 문제점**
    
    → CelebA나 RaFD 데이터셋에서 CelebA는 머리색과 성별과 같은 라벨을 포함한 반면, 행복, 분노와 같은 표정에 관한 라벨은 가지고 있지 않음
    

- **모든 데이터셋이 동등하게 라벨을 가지고 있는 것이 아니라 어떤 데이터셋은 특정 라벨만 가지고 있고 다른 데이터셋은 또 그 데이터셋만의 라벨을 가지고 있다는 것**
- 변환된 이미지 G(x,c)에서 Input image x를 Reconstructing 하는 과정에서 라벨 벡터 c'에 대한 완전한 정보가 필요하기 때문에 문제가 됨

## Mask Vector

- 위의 문제점( 라벨을 부분적으로만 가지고 있는 문제 )를 완화시키기 위해서, 이 논문에서는 ***mask vector m***를 제안
- 이 mask vector는 StarGAN이 **특정화되지 않은 라벨들을 무시**하고 특정 데이터 셋에서 존재하는 확실히 알려진 라벨에 초점을 맞추도록 함
    
    → 예를 들어, CelebA의 데이터셋에서 행복과 같은 라벨은 무시하고 머리색과 같은 라벨에 초점을 맞추도록 함
    

- StarGAN에서는 ***mask vector m***을 표현하기 위해 **n차원의 one-hot vector**를 사용하는데 n은 데이터셋의 수를 뜻

![Untitled](StarGAN%20ce6b28c764f74b1592f0ae2846d595d5/Untitled%2010.png)

- $C_i$는 $i$번째의 dataset의 label들의 vector를 나타냄
- 또한 $C_i$는 binary attribute를 가진 binary vector 또는 categorical attribute를 가진 one-hot vector임
- dataset은 Celeb A와 RaFD이기 때문에 n은 2가 됨.

- mask vector에 어떤 dataset 인지를 명시해 줌으로써, 해당 dataset의 attribute에 관련된 label에 집중을 함
    
    → CelebA를 학습시키려고 명시해 주었다면 RaFD에 관련된 facial expression들은 무시하고 학습하는 것을 말함
    

- CelebA와 RaFD를 교차시킴으로써 D(판별자)는 두 dataset에서 차이를 구분 짓는 모든 feature들을 학습하게 되고, G(생성자)는 모든 label을 컨트롤하는 것을 학습

![Untitled](StarGAN%20ce6b28c764f74b1592f0ae2846d595d5/Untitled%2011.png)

# ****Implementation****

### **Improved GAN Training**

- 학습 과정을 안정화시키고 더 좋은 퀄리티의 이미지들을 만들어내기 위해 이 논문에서는 Eq(1)을 **gradient penalty**와 함께 **Wasserstein GAN**으로 대체함

![https://blog.kakaocdn.net/dn/bLvujA/btqU0ygxmCi/TwvIKjAFhKFAekFQapleQk/img.png](https://blog.kakaocdn.net/dn/bLvujA/btqU0ygxmCi/TwvIKjAFhKFAekFQapleQk/img.png)

### **Network Architecture**

- StarGAN은 두 개의 convolutional layers로 구성된 (stride size of 2 for downsampling, & 6 residual blocks and 2 transposed convolutional layers with the stride size of 2 for upsampling.) **generator network**을 가짐
- 또한 generator에 instance normalization을 사용하고 discriminator에는 사용하지 않음

# ****Experiments****

**On RaFD**

![https://blog.kakaocdn.net/dn/dGJiEw/btqURvfaThi/BgCyeZ8Kq6AMl6rlmxGbY0/img.png](https://blog.kakaocdn.net/dn/dGJiEw/btqURvfaThi/BgCyeZ8Kq6AMl6rlmxGbY0/img.png)

**On CelebA+RaFD**

![https://blog.kakaocdn.net/dn/8JEsC/btqUWtmXBa8/IR4eNPtSJG0oz0M9rvEcF1/img.png](https://blog.kakaocdn.net/dn/8JEsC/btqUWtmXBa8/IR4eNPtSJG0oz0M9rvEcF1/img.png)

# Conclusion

- 단일 Generator와 Discriminator를 사용하는 다중 도메인 간의 확장 가능한 이미지 변환 모델을 제시함
- Multi-task 학습 환경의 일반화 성능 분석을 통해서 비약적으로 성능을 향상
- Mask vector를 통해서 서로 다른 domain label set를 가진 multiple dataset를 활용할 수 있으므로 사용 가능한 모든 label을 처리할 수 있음

# 참고 링크

- 유튜브

[StarGAN (꼼꼼한 딥러닝 논문 리뷰와 코드 실습)](https://www.youtube.com/watch?v=-r9M4Cj9o_8)

[[논문 리뷰] StarGAN - 김인재](https://www.youtube.com/watch?v=JsykdqIC7Qg)

- 블로그

[[논문 리뷰] StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation](https://simonezz.tistory.com/70)

[[논문 리뷰] StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation](https://eunchankim-dev.tistory.com/40)

[](https://aistudy9314.tistory.com/52)

- 깃허브

[summary pdf](https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/lecture_notes/StarGAN.pdf)

[StarGAN py](https://github.com/yunjey/stargan)

[Deep-Learning-Paper-Review-and-Practice/StarGAN_Tutorial.ipynb at master · ndb796/Deep-Learning-Paper-Review-and-Practice](https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/StarGAN_Tutorial.ipynb)
